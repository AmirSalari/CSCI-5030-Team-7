{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import re\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import random\n","from tqdm import tqdm\n","import tensorflow.keras\n","import tensorflow as tf\n","from sklearn.metrics import fbeta_score\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.layers import Embedding,LSTM, TimeDistributed, Dense, Bidirectional\n","from tensorflow.keras.initializers import HeNormal, GlorotNormal, GlorotUniform\n","from nltk.translate.bleu_score import sentence_bleu\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = pd.read_csv('preprocessed_15.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pd.options.display.max_colwidth = 500\n","data[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess(t, add_start_token, add_end_token):\n","\n","  if add_start_token == True and add_end_token == False:\n","    t = '<start>'+' '+t\n","  if add_start_token == False and add_end_token == True:\n","    t = t+' '+'<end>'\n","  if add_start_token == True and add_end_token == True:\n","    t = '<start>'+' '+t+' '+'<end>'\n","\n","  t = re.sub(' +', ' ', t)\n","  return t"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder_input = [preprocess(line, add_start_token= True, add_end_token=True) for line in data['error']]\n","decoder_input = [preprocess(line, add_start_token= True, add_end_token=False) for line in data['correct']]\n","decoder_output = [preprocess(line, add_start_token= False, add_end_token=True) for line in data['correct']]\n","print(encoder_input[0])\n","print(decoder_input[0])\n","print(decoder_output[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#ENCODER INPUT\n","\n","tokenizer = Tokenizer(filters='', split=\" \")\n","tokenizer.fit_on_texts(encoder_input)\n","word_index = tokenizer.word_index #vocabulary\n","\n","max_length = max([ len(row.split(\" \")) for row in encoder_input ])\n","INPUT_ENCODER_LENGTH = max_length\n","\n","enc_input_encoded = tokenizer.texts_to_sequences(encoder_input)\n","enc_input_padded= pad_sequences(enc_input_encoded, maxlen=INPUT_ENCODER_LENGTH, padding=\"post\")\n","\n","print(enc_input_padded.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(encoder_input[0])\n","print(enc_input_padded[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#DECODER INPUT\n","decoder_data = decoder_input.copy()\n","decoder_data.extend(decoder_output)\n","\n","out_tokenizer = Tokenizer(filters='', split=\" \")\n","out_tokenizer.fit_on_texts(decoder_data)\n","word_index = out_tokenizer.word_index #vocabulary\n","\n","max_length = max([ len(row.split(\" \")) for row in decoder_input ])\n","INPUT_DECODER_LENGTH = max_length"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dec_input_encoded = out_tokenizer.texts_to_sequences(decoder_input)\n","dec_input_padded= pad_sequences(dec_input_encoded, maxlen=INPUT_DECODER_LENGTH, padding=\"post\", truncating = \"post\")\n","\n","print(dec_input_padded.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(decoder_input[0])\n","print(dec_input_padded[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dec_output_encoded = out_tokenizer.texts_to_sequences(decoder_output)\n","dec_output_padded= pad_sequences(dec_output_encoded, maxlen=INPUT_DECODER_LENGTH, padding=\"post\", truncating = \"post\")\n","\n","print(dec_output_padded.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(decoder_output[1])\n","print(dec_output_padded[1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Reference: https://fasttext.cc/docs/en/english-vectors.html\n","import io\n","\n","def load_vectors(fname):\n","    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n","    n, d = map(int, fin.readline().split())\n","    data = {}\n","    for line in fin:\n","        tokens = line.rstrip().split(' ')\n","        data[tokens[0]] = np.asarray(tokens[1:])#map(float, tokens[1:])\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["embedding_index = load_vectors('wiki-news-300d-1M.vec')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#https://keras.io/examples/nlp/pretrained_word_embeddings/\n","word_index = tokenizer.word_index\n","num_tokens = len(word_index) + 2\n","embedding_dim = 300\n","hits = 0\n","misses = 0\n","\n","embedding_matrix = np.zeros((num_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embedding_index.get(word)\n","\n","    if type(embedding_vector) == np.ndarray and embedding_vector.shape[0] == 300:  \n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","\n","    else:\n","        misses += 1\n","print(\"Converted %d words (%d misses)\" % (hits, misses))\n","np.save('GEC/in_embedding.npy', embedding_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["word_index = out_tokenizer.word_index\n","num_tokens = len(word_index) + 2\n","embedding_dim = 300\n","hits = 0\n","misses = 0\n","\n","embedding_matrix = np.zeros((num_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embedding_index.get(word)\n","\n","    if type(embedding_vector) == np.ndarray and embedding_vector.shape[0] == 300:  \n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","\n","    else:\n","        misses += 1\n","print(\"Converted %d words (%d misses)\" % (hits, misses))\n","np.save('GEC/out_embedding.npy', embedding_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["in_embedding_matrix = np.load('GEC/in_embedding.npy')\n","out_embedding_matrix = np.load('GEC/out_embedding.npy')\n","print(in_embedding_matrix.shape, out_embedding_matrix.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#ENCODER\n","class Encoder(tf.keras.Model):\n","    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n","        super().__init__()\n","        self.vocab_size = inp_vocab_size\n","        self.embedding_size = embedding_size\n","        self.lstm_units = lstm_size\n","        self.input_length = input_length\n","\n","def build(self, input_sequence):\n","        #self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length, \n","        #                           #embeddings_initializer=keras.initializers.Constant(in_embedding_matrix), mask_zero=True, \n","        #                           weights = [in_embedding_matrix], mask_zero=True, \n","        #                           trainable = False, name=\"embedding_layer_encoder\")\n","        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n","                           mask_zero=True, name=\"embedding_layer_encoder\")\n","        self.lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n","\n","    def call(self,input_sequence,states, training = True):\n","        input_embedding = self.embedding(input_sequence)   #(batch_size, length of input array, embedding_size)\n","        self.lstm_output, self.state_h, self.state_c = self.lstm(input_embedding, initial_state = states)\n","        return self.lstm_output,self.state_h, self.state_c\n","\n","\n","    def initialize_states(self,batch_size):\n","      initializer = GlorotNormal()\n","      lstm_state_h = initializer(shape=(batch_size, self.lstm_units))#tf.zeros((batch_size, self.lstm_units), dtype=tf.dtypes.float32, name=\"Encoder_LSTM_hidden_state\")\n","      lstm_state_c = initializer(shape=(batch_size, self.lstm_units))#tf.zeros((batch_size, self.lstm_units), dtype=tf.dtypes.float32, name=\"Encoder_LSTM_cell_state\")\n","      return lstm_state_h, lstm_state_c\n","\n","\n","#DECODER\n","class Decoder(tf.keras.Model):\n","    def init(self,out_vocab_size,embedding_size,lstm_size,input_length):\n","        super().init()\n","        self.vocab_size = out_vocab_size\n","        self.embedding_size = embedding_size\n","        self.lstm_units = lstm_size\n","        self.input_length = input_length\n","\n","\n","    def build(self,input_sequence):\n","        #self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length, \n","        #                           #embeddings_initializer=keras.initializers.Constant(out_embedding_matrix), \n","        #                           weights = [out_embedding_matrix], mask_zero=True, \n","        #                           trainable = False, name=\"embedding_layer_decoder\")\n","        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n","                           mask_zero=True, name=\"embedding_layer_decoder\") \n","        self.lstm = LSTM(self.lstm_units, return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n","\n","\n","    def call(self,input_sequence,initial_states, training = True):\n","\n","        input_embedding = self.embedding(input_sequence)\n","        self.lstm_output, self.state_h, self.state_c = self.lstm(input_embedding, initial_state=initial_states)\n","        return self.lstm_output,self.state_h, self.state_c"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"GEC_Baseline_Encoder_Decoder.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
